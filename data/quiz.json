[
  {
    "id": 1,
    "type": "基礎知識",
    "question": "Transformerアーキテクチャの主な特徴は？",
    "options": ["畳み込みニューラルネットワーク", "注意機構（Attention Mechanism）", "決定木アルゴリズム", "マルコフ連鎖モデル"],
    "correctAnswer": 2
  },
  {
    "id": 2,
    "type": "基礎知識",
    "question": "LLMの事前学習で一般的に使用されるデータは？",
    "options": ["数値計算表", "構造化データベース", "ウェブテキストコーパス", "センサーデータ"],
    "correctAnswer": 3
  },
  {
    "id": 3,
    "type": "基礎知識",
    "question": "日本語言語処理の課題として適切でないものは？",
    "options": ["漢字の多様な読み方", "敬語表現の複雑さ", "単語間のスペース区切り", "方言の多様性"],
    "correctAnswer": 3
  },
  {
    "id": 4,
    "type": "技術的理解",
    "question": "ファインチューニングの主な目的は？",
    "options": ["計算リソースの削減", "特定タスクへの適応", "モデルサイズの拡大", "訓練データの生成"],
    "correctAnswer": 2
  },
  {
    "id": 5,
    "type": "倫理",
    "question": "AI倫理で議論される「アルゴリズムバイアス」とは？",
    "options": ["計算速度の偏り", "訓練データ反映の社会的偏見", "プログラミング言語の制約", "ハードウェアの熱暴走"],
    "correctAnswer": 2
  },
  {
    "id": 6,
    "type": "基礎知識",
    "question": "GPT-4がLlama 2より優れているとされる分野は？",
    "options": ["計算効率", "生成文章の自然さ", "メモリ使用量", "訓練速度"],
    "correctAnswer": 2
  },
  {
    "id": 7,
    "type": "応用",
    "question": "教育現場でのAI利用で最も懸念される点は？",
    "options": ["電力消費量", "思考プロセスの省略化", "インターフェースの操作性", "ファイル保存形式"],
    "correctAnswer": 2
  },
  {
    "id": 8,
    "type": "倫理",
    "question": "AI生成テキスト検出ツールの課題は？",
    "options": ["検出精度の不安定性", "色表示の不鮮明さ", "ファイルサイズ制限", "言語選択の限界"],
    "correctAnswer": 1
  },
  {
    "id": 9,
    "type": "基礎知識",
    "question": "日本語言語モデル評価に適したデータセットは？",
    "options": ["MNIST", "JGLUE", "ImageNet", "COCO"],
    "correctAnswer": 2
  },
  {
    "id": 10,
    "type": "高度概念",
    "question": "「テキスト情報量」（text informativity）の計算式は？",
    "options": ["回答精度（テキストあり） - 推測精度（テキストなし）", "単語数 × 文の長さ", "固有表現出現頻度", "文脈ベクトルの余弦類似度"],
    "correctAnswer": 1
  },
  {
    "id": 11,
    "type": "高度概念",
    "question": "マルチモーダル学習の利点でないものは？",
    "options": ["テキストと画像の統合理解", "単一データ型への依存強化", "現実世界タスクへの適応力", "表現力の多様化"],
    "correctAnswer": 2
  },
  {
    "id": 12,
    "type": "応用",
    "question": "日本語言語モデルが苦手とするタスクは？",
    "options": ["漢字変換", "建前と本音の識別", "単語分割", "敬語生成"],
    "correctAnswer": 2
  },
  {
    "id": 13,
    "type": "技術的理解",
    "question": "JGLUEベンチマークが測定しない能力は？",
    "options": ["文書読解力", "質問応答精度", "画像分類精度", "常識推論力"],
    "correctAnswer": 3
  },
  {
    "id": 14,
    "type": "技術的理解",
    "question": "Few-shot学習の利点でないものは？",
    "options": ["少量データでの適応", "計算コスト削減", "事前知識の再利用", "モデル再訓練の必要性"],
    "correctAnswer": 4
  },
  {
    "id": 15,
    "type": "技術的理解",
    "question": "マルチモーダルモデルが苦手とするタスクは？",
    "options": ["画像キャプション生成", "テキスト要約", "音声テキスト変換", "数式推論"],
    "correctAnswer": 4
  },
  {
    "id": 16,
    "type": "技術的理解",
    "question": "日本語LLMの訓練で効果的な手法は？",
    "options": ["英語データのみ使用", "継続的事前学習（Continual Pre-training）", "パラメータ数削減", "バッチサイズ拡大"],
    "correctAnswer": 2
  },
  {
    "id": 17,
    "type": "倫理",
    "question": "AI倫理で「説明可能性」が重視される理由は？",
    "options": ["計算速度向上のため", "ユーザー信頼獲得のため", "モデル圧縮のため", "データ収集効率化のため"],
    "correctAnswer": 2
  },
  {
    "id": 18,
    "type": "技術的理解",
    "question": "モデル蒸留（Distillation）の主目的は？",
    "options": ["モデルサイズ縮小", "訓練データ増加", "ハードウェア互換性向上", "評価基準統一"],
    "correctAnswer": 1
  },
  {
    "id": 19,
    "type": "応用",
    "question": "医療分野でのLLM利用リスクは？",
    "options": ["診断精度の過信", "電力消費増加", "メ文字化け発生", "レスポンス速度低下"],
    "correctAnswer": 1
  },
  {
    "id": 20,
    "type": "応用",
    "question": "プライバシー保護技術で適切でないものは？",
    "options": ["差分プライバシー", "データ匿名化", "モデル公開", "フェデレーテッドラーニング"],
    "correctAnswer": 3
  },
  {
    "id": 21,
    "type": "倫理",
    "question": "AI生成コンテンツの著作権問題で正しいのは？",
    "options": ["完全に著作権フリー", "訓練データの出典開示が必要さ", "商用利用は常に禁止", "日本法では未整備"],
    "correctAnswer": 4
  },
  {
    "id": 22,
    "type": "倫理",
    "question": "バイアス軽減に有効な手法は？",
    "options": ["データ拡張", "ドメイン適応", "デバイアシングフィルタ", "量子化"],
    "correctAnswer": 3
  },
  {
    "id": 23,
    "type": "技術的理解",
    "question": "対話システムの評価指標でないものは？",
    "options": ["BLEUスコア", "ROUGEスコア", "TERスコア", "FLOPS"],
    "correctAnswer": 4
  },
  {
    "id": 24,
    "type": "応用",
    "question": "災害情報処理でLLMが注意すべき点は？",
    "options": ["時系列情報の更新", "文字コード変換", "バッチ処理最適化", "GPUメモリ節約"],
    "correctAnswer": 1
  },
  {
    "id": 25,
    "type": "技術的理解",
    "question": "知識蒸留の効果でないものは？",
    "options": ["推論速度向上", "メモリ使用量削減", "モデル表現力拡大", "デプロイ容易化"],
    "correctAnswer": 3
  },
  {
    "id": 26,
    "type": "高度概念",
    "question": "日本語言語モデルの文脈窓拡大がもたらす影響は？",
    "options": ["長期依存関係の把握", "計算効率向上さ", "訓練データ削減", "語彙数減少"],
    "correctAnswer": 1
  },
  {
    "id": 27,
    "type": "高度概念",
    "question": "Few-shot学習が有効でないタスクは？",
    "options": ["感情分析", "専門用語翻訳", "数式証明", "定型文生成"],
    "correctAnswer": 3
  },
  {
    "id": 28,
    "type": "高度概念",
    "question": "マルチタスク学習のデメリットは？",
    "options": ["タスク間干渉", "推論速度低下", "メタデータ必要", "GPUメモリ増加"],
    "correctAnswer": 1
  },
  {
    "id": 29,
    "type": "応用",
    "question": "AI評価システム導入時の重要な検討事項は？",
    "options": ["ハードウェアの色調", "評価基準の透明性確保", "ファイル命名規則", "インターネット接続速度"],
    "correctAnswer": 2
  },
  {
    "id": 30,
    "type": "高度概念",
    "question": "今後の言語モデル開発で最重要とされる要素は？",
    "options": ["パラメータ数の増大", "倫理的フレームワークの構築", "グラフィック性能", "グラフィック性能"],
    "correctAnswer": 2
  }
]
